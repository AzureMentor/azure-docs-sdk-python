### YamlMime:UniversalReference
api_name: []
items:
- example:
  - '

    ```


    >>> from io import BytesIO  # doctest: +SKIP

    >>> f = BytesIO(b''Alice, 100\nBob, 200\nCharlie, 300'')  # doctest: +SKIP

    >>> read_block(f, 0, 13)  # doctest: +SKIP

    b''Alice, 100\nBo''

    ```



    ```


    >>> read_block(f, 0, 13, delimiter=b''\n'')  # doctest: +SKIP

    b''Alice, 100\n''

    ```



    ```


    >>> read_block(f, 10, 10, delimiter=b''\n'')  # doctest: +SKIP

    b''\nCharlie, 300''

    >>> f  = BytesIO(bytearray(2**22))  # doctest: +SKIP

    >>> read_block(f,0,2**22, delimiter=b''\n'')  # doctest: +SKIP

    IndexError: No delimiter found within max record size of 4MB.

    Transfer without specifying a delimiter (as binary) instead.

    ```

    '
  - '

    ```


    >>> from io import BytesIO  # doctest: +SKIP

    >>> f = BytesIO(b''Alice, 100\nBob, 200\nCharlie, 300'')  # doctest: +SKIP

    >>> read_block(f, 0, 13)  # doctest: +SKIP

    b''Alice, 100\nBo''

    ```



    ```


    >>> read_block(f, 0, 13, delimiter=b''\n'')  # doctest: +SKIP

    b''Alice, 100\n''

    ```



    ```


    >>> read_block(f, 10, 10, delimiter=b''\n'')  # doctest: +SKIP

    b''\nCharlie, 300''

    >>> f  = BytesIO(bytearray(2**22))  # doctest: +SKIP

    >>> read_block(f,0,2**22, delimiter=b''\n'')  # doctest: +SKIP

    IndexError: No delimiter found within max record size of 4MB.

    Transfer without specifying a delimiter (as binary) instead.

    ```

    '
  fullName: azure.datalake.store.utils.read_block
  langs:
  - python
  module: azure.datalake.store.utils
  name: read_block(f, offset, length, delimiter=None)
  source:
    id: read_block
    path: azure\datalake\store\utils.py
    remote:
      branch: master
      path: azure\datalake\store\utils.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 45
  summary: Read a block of bytes from a file
  syntax:
    content: read_block(f, offset, length, delimiter=None)
    parameters:
    - description: a file object that supports seek, tell and read.
      id: fn
      type:
      - file object
    - description: Byte offset to start read
      id: offset
      type:
      - int
    - description: Maximum number of bytes to read
      id: length
      type:
      - int
    - defaultValue: None
      description: Ensure reading stops at delimiter bytestring
      id: delimiter
      type:
      - bytes (optional)
    - description: ''
      id: using the delimiter= keyword argument we ensure that the read
      type:
      - If
    - description: ''
      id: at or before the delimiter boundaries that follow the location
      type:
      - stops
    - description: ''
      id: + length. For ADL, if no delimiter is found and the data
      type:
      - offset
    - description: ''
      id: is > 4MB an exception is raised, since a single record cannot
      type:
      - requested
    - description: ''
      id: 4MB and be guaranteed to land contiguously in ADL.
      type:
      - exceed
    - description: ''
      id: bytestring returned WILL include the
      type:
      - The
    - description: ''
      id: delimiter string.
      type:
      - terminating
  type: function
  uid: azure.datalake.store.utils.read_block
references:
- fullName: bytes (optional)
  name: bytes (optional)
  spec.python:
  - fullName: 'bytes '
    name: 'bytes '
    uid: 'bytes '
  - fullName: (
    name: (
  - fullName: optional
    name: optional
    uid: optional
  - fullName: )
    name: )
  uid: bytes (optional)
