### YamlMime:UniversalReference
api_name: []
items:
- children:
  - azure.cognitiveservices.speech.PropertyId.AudioConfig_AudioSource
  - azure.cognitiveservices.speech.PropertyId.AudioConfig_BitsPerSampleForCapture
  - azure.cognitiveservices.speech.PropertyId.AudioConfig_DeviceNameForCapture
  - azure.cognitiveservices.speech.PropertyId.AudioConfig_NumberOfChannelsForCapture
  - azure.cognitiveservices.speech.PropertyId.AudioConfig_SampleRateForCapture
  - azure.cognitiveservices.speech.PropertyId.CancellationDetails_Reason
  - azure.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonDetailedText
  - azure.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonText
  - azure.cognitiveservices.speech.PropertyId.LanguageUnderstandingServiceResponse_JsonResult
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Token
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Type
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Endpoint
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EndpointId
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_IntentRegion
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Key
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyHostName
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPassword
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPort
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyUserName
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoLanguage
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoMode
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Region
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthLanguage
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOutputFormat
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthVoice
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationFeatures
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationToLanguages
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationVoice
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonErrorDetails
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonResult
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RecognitionLatencyMs
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse
  - azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse
  - azure.cognitiveservices.speech.PropertyId.Speech_LogFilename
  - azure.cognitiveservices.speech.PropertyId.Speech_SessionId
  class: azure.cognitiveservices.speech.PropertyId
  fullName: azure.cognitiveservices.speech.PropertyId
  inheritance:
  - inheritance:
    - type: builtins.object
    type: enum.Enum
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: PropertyId
  summary: "Defines speech property ids.\n\n*Values:*\n\n   SpeechServiceConnection_Key\n\
    \n\n      The Cognitive Services Speech Service subscription key. If you are using\n\
    \n      an intent recognizer, you need to specify the LUIS endpoint key for your\n\
    \n      particular LUIS app. Under normal circumstances, you shouldn't have to\n\
    \n      use this property directly. Instead, construct a\n\n      <xref:azure.cognitiveservices.speech.SpeechConfig>\
    \ instance from a subscription key.\n\n   SpeechServiceConnection_Endpoint\n\n\
    \n      The Cognitive Services Speech Service endpoint (url). Under normal\n\n\
    \      circumstances, you shouldn't have to use this property directly. Instead,\n\
    \n      construct a <xref:azure.cognitiveservices.speech.SpeechConfig> instance\
    \ from a subscription key.\n\n\n      > [!NOTE]\n      > This endpoint is not\
    \ the same as the endpoint used to obtain an access token.\n      >\n\n   SpeechServiceConnection_Region\n\
    \n\n      The Cognitive Services Speech Service region. Under normal circumstances,\n\
    \n      you shouldn't have to use this property directly. Instead, construct a\n\
    \n      <xref:azure.cognitiveservices.speech.SpeechConfig> instance from a subscription\
    \ key, an endpoint\n\n      or an authorization token.\n\n   SpeechServiceAuthorization_Token\n\
    \n\n      The Cognitive Services Speech Service authorization token (aka access\n\
    \n      token). Under normal circumstances, you shouldn't have to use this\n\n\
    \      property directly. Instead, construct a <xref:azure.cognitiveservices.speech.SpeechConfig>\n\
    \n      instance from an authorization token, or set\n\n      <xref:Recognizer.authorization_token>.\n\
    \n   SpeechServiceAuthorization_Type\n\n\n      The Cognitive Services Speech\
    \ Service authorization type. Currently\n\n      unused.\n\n   SpeechServiceConnection_EndpointId\n\
    \n\n      The Cognitive Services Custom Speech Service endpoint id. Under normal\n\
    \n      circumstances, you shouldn't have to use this property directly. Instead\n\
    \n      set <xref:SpeechConfig.endpoint_id>.\n\n\n      > [!NOTE]\n      > The\
    \ endpoint id is available in the Custom Speech Portal, listed under\n      >\n\
    \      > \n      >\n      > Endpoint Details.\n      >\n\n   SpeechServiceConnection_ProxyHostName\n\
    \n\n      The host name of the proxy server used to connect to the Cognitive\n\
    \n      Services Speech Service. Under normal circumstances, you shouldn't have\n\
    \n      to use this property directly. Instead, use\n\n      <xref:SpeechConfig.set_proxy>.\n\
    \n   SpeechServiceConnection_ProxyPort\n\n\n      The port of the proxy server\
    \ used to connect to the Cognitive Services\n\n      Speech Service. Under normal\
    \ circumstances, you shouldn't have to use\n\n      this property directly. Instead,\
    \ use <xref:SpeechConfig.set_proxy>.\n\n   SpeechServiceConnection_ProxyUserName\n\
    \n\n      The user name of the proxy server used to connect to the Cognitive\n\
    \n      Services Speech Service. Under normal circumstances, you shouldn't have\n\
    \n      to use this property directly. Instead, use\n\n      <xref:SpeechConfig.set_proxy>.\n\
    \n   SpeechServiceConnection_ProxyPassword\n\n\n      The password of the proxy\
    \ server used to connect to the Cognitive\n\n      Services Speech Service. Under\
    \ normal circumstances, you shouldn't have\n\n      to use this property directly.\
    \ Instead, use\n\n      <xref:SpeechConfig.set_proxy>.\n\n   SpeechServiceConnection_TranslationToLanguages\n\
    \n\n      The list of comma separated languages used as target translation\n\n\
    \      languages. Under normal circumstances, you shouldn't have to use this\n\
    \n      property directly. Instead use\n\n      <xref:SpeechTranslationConfig.add_target_language>\
    \ and\n\n      <xref:SpeechTranslationConfig.target_languages>.\n\n   SpeechServiceConnection_TranslationVoice\n\
    \n\n      The name of the Cognitive Service Text to Speech Service voice. Under\n\
    \n      normal circumstances, you shouldn't have to use this property directly.\n\
    \n      Instead set <xref:SpeechTranslationConfig.voice_name>.\n\n\n      > [!NOTE]\n\
    \      > Valid voice names can be found [here](https://aka.ms/csspeech/voicenames).\n\
    \      >\n\n   SpeechServiceConnection_TranslationFeatures\n\n\n      Translation\
    \ features. For internal use.\n\n   SpeechServiceConnection_IntentRegion\n\n\n\
    \      The Language Understanding Service region. Under normal circumstances,\n\
    \n      you shouldn't have to use this property directly. Instead use\n\n    \
    \  <xref:azure.cognitiveservices.speech.LanguageUnderstandingModel>.\n\n   SpeechServiceConnection_RecoMode\n\
    \n\n      The Cognitive Services Speech Service recognition mode. Can be\n\n \
    \     \"INTERACTIVE\", \"CONVERSATION\", \"DICTATION\". This property is intended\
    \ to\n\n      be read-only. The SDK is using it internally.\n\n   SpeechServiceConnection_RecoLanguage\n\
    \n\n      The spoken language to be recognized (in BCP-47 format). Under normal\n\
    \n      circumstances, you shouldn't have to use this property directly. Instead,\n\
    \n      use <xref:SpeechConfig.speech_recognition_language>.\n\n   Speech_SessionId\n\
    \n\n      The session id. This id is a universally unique identifier (aka UUID)\n\
    \n      representing a specific binding of an audio input stream and the\n\n \
    \     underlying speech recognition instance to which it is bound. Under normal\n\
    \n      circumstances, you shouldn't have to use this property directly. Instead\n\
    \n      use <xref:SessionEventArgs.session_id>.\n\n   SpeechServiceResponse_RequestDetailedResultTrueFalse\n\
    \n\n      The requested Cognitive Services Speech Service response output format\n\
    \n      (simple or detailed). Under normal circumstances, you shouldn't have to\n\
    \n      use this property directly. Instead use\n\n      <xref:SpeechConfig.output_format>.\n\
    \n   SpeechServiceResponse_RequestProfanityFilterTrueFalse\n\n\n      The requested\
    \ Cognitive Services Speech Service response output profanity\n\n      level.\
    \ Currently unused.\n\n   SpeechServiceResponse_JsonResult\n\n\n      The Cognitive\
    \ Services Speech Service response output (in JSON format).\n\n      This property\
    \ is available as <xref:RecognitionResult.json>.\n\n   SpeechServiceResponse_JsonErrorDetails\n\
    \n\n      The Cognitive Services Speech Service error details (in JSON format).\n\
    \n      Under normal circumstances, you shouldn't have to use this property\n\n\
    \      directly. This property is available as\n\n      <xref:RecognitionResult.error_json>.\n\
    \n   SpeechServiceResponse_RecognitionLatencyMs\n\n\n      The recognition latency\
    \ in milliseconds. Read-only, available on final\n\n      speech/translation/intent\
    \ results. This measures the latency between\n\n      when an audio input is received\
    \ by the SDK, and the moment the final\n\n      result is received from the service.\
    \ The SDK computes the time\n\n      difference between the last audio fragment\
    \ from the audio input that is\n\n      contributing to the final result, and\
    \ the time the final result is\n\n      received from the speech service.\n\n\n\
    \      > [!NOTE]\n      > This property id was added in version 1.3.0.\n     \
    \ >\n\n   CancellationDetails_Reason\n\n\n      The cancellation reason. Currently\
    \ unused.\n\n   CancellationDetails_ReasonText\n\n\n      The cancellation text.\
    \ Currently unused.\n\n   CancellationDetails_ReasonDetailedText\n\n\n      The\
    \ cancellation detailed text. Currently unused.\n\n   LanguageUnderstandingServiceResponse_JsonResult\n\
    \n\n      The Language Understanding Service response output (in JSON format).\n\
    \n      This property is available as\n\n      <xref:IntentRecognitionResult.intent_json>.\n\
    \n   AudioConfig_DeviceNameForCapture\n\n\n      The device name for audio capture.\
    \ Under normal circumstances, you shouldn't have to\n\n      use this property\
    \ directly.\n\n      Instead, use the *device_name* parameter to construct a *AudioConfig*\
    \ instance.\n\n\n      > [!NOTE]\n      > This property id was added in version\
    \ 1.3.0.\n      >\n\n   AudioConfig_NumberOfChannelsForCapture\n\n\n      The\
    \ number of channels for audio capture. Internal use only.\n\n\n      > [!NOTE]\n\
    \      > This property id was added in version 1.3.0.\n      >\n\n   AudioConfig_SampleRateForCapture\n\
    \n\n      The sample rate (in Hz) for audio capture. Internal use only.\n\n\n\
    \      > [!NOTE]\n      > This property id was added in version 1.3.0.\n     \
    \ >\n\n   AudioConfig_BitsPerSampleForCapture\n\n\n      The number of bits of\
    \ each sample for audio capture. Internal use only.\n\n\n      > [!NOTE]\n   \
    \   > This property id was added in version 1.3.0.\n      >\n\n   AudioConfig_AudioSource\n\
    \n\n      The audio source. Allowed values are \"Microphones\", \"File\", and\
    \ \"Stream\".\n\n\n      > [!NOTE]\n      > This property id was added in version\
    \ 1.3.0.\n      >"
  syntax: {}
  type: class
  uid: azure.cognitiveservices.speech.PropertyId
- fullName: azure.cognitiveservices.speech.PropertyId.AudioConfig_AudioSource
  id: AudioConfig_AudioSource
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: AudioConfig_AudioSource
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The audio source. Allowed values are "Microphones", "File", and "Stream".



    > [!NOTE]

    > This property id was added in version 1.3.0.

    >'
  syntax:
    content: AudioConfig_AudioSource = 8004
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_AudioSource
- fullName: azure.cognitiveservices.speech.PropertyId.AudioConfig_BitsPerSampleForCapture
  id: AudioConfig_BitsPerSampleForCapture
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: AudioConfig_BitsPerSampleForCapture
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The number of bits of each sample for audio capture. Internal use only.



    > [!NOTE]

    > This property id was added in version 1.3.0.

    >'
  syntax:
    content: AudioConfig_BitsPerSampleForCapture = 8003
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_BitsPerSampleForCapture
- fullName: azure.cognitiveservices.speech.PropertyId.AudioConfig_DeviceNameForCapture
  id: AudioConfig_DeviceNameForCapture
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: AudioConfig_DeviceNameForCapture
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The device name for audio capture. Under normal circumstances, you shouldn''t
    have to


    use this property directly.


    Instead, use the *device_name* parameter to construct a *AudioConfig* instance.



    > [!NOTE]

    > This property id was added in version 1.3.0.

    >'
  syntax:
    content: AudioConfig_DeviceNameForCapture = 8000
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_DeviceNameForCapture
- fullName: azure.cognitiveservices.speech.PropertyId.AudioConfig_NumberOfChannelsForCapture
  id: AudioConfig_NumberOfChannelsForCapture
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: AudioConfig_NumberOfChannelsForCapture
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The number of channels for audio capture. Internal use only.



    > [!NOTE]

    > This property id was added in version 1.3.0.

    >'
  syntax:
    content: AudioConfig_NumberOfChannelsForCapture = 8001
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_NumberOfChannelsForCapture
- fullName: azure.cognitiveservices.speech.PropertyId.AudioConfig_SampleRateForCapture
  id: AudioConfig_SampleRateForCapture
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: AudioConfig_SampleRateForCapture
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The sample rate (in Hz) for audio capture. Internal use only.



    > [!NOTE]

    > This property id was added in version 1.3.0.

    >'
  syntax:
    content: AudioConfig_SampleRateForCapture = 8002
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_SampleRateForCapture
- fullName: azure.cognitiveservices.speech.PropertyId.CancellationDetails_Reason
  id: CancellationDetails_Reason
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: CancellationDetails_Reason
  parent: azure.cognitiveservices.speech.PropertyId
  summary: The cancellation reason. Currently unused.
  syntax:
    content: CancellationDetails_Reason = 6000
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.CancellationDetails_Reason
- fullName: azure.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonDetailedText
  id: CancellationDetails_ReasonDetailedText
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: CancellationDetails_ReasonDetailedText
  parent: azure.cognitiveservices.speech.PropertyId
  summary: The cancellation detailed text. Currently unused.
  syntax:
    content: CancellationDetails_ReasonDetailedText = 6002
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonDetailedText
- fullName: azure.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonText
  id: CancellationDetails_ReasonText
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: CancellationDetails_ReasonText
  parent: azure.cognitiveservices.speech.PropertyId
  summary: The cancellation text. Currently unused.
  syntax:
    content: CancellationDetails_ReasonText = 6001
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonText
- fullName: azure.cognitiveservices.speech.PropertyId.LanguageUnderstandingServiceResponse_JsonResult
  id: LanguageUnderstandingServiceResponse_JsonResult
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: LanguageUnderstandingServiceResponse_JsonResult
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The Language Understanding Service response output (in JSON format).


    This property is available as


    <xref:IntentRecognitionResult.intent_json>.'
  syntax:
    content: LanguageUnderstandingServiceResponse_JsonResult = 7000
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.LanguageUnderstandingServiceResponse_JsonResult
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Token
  id: SpeechServiceAuthorization_Token
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceAuthorization_Token
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The Cognitive Services Speech Service authorization token (aka access


    token). Under normal circumstances, you shouldn''t have to use this


    property directly. Instead, construct a <xref:azure.cognitiveservices.speech.SpeechConfig>


    instance from an authorization token, or set


    <xref:Recognizer.authorization_token>.'
  syntax:
    content: SpeechServiceAuthorization_Token = 1003
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Token
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Type
  id: SpeechServiceAuthorization_Type
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceAuthorization_Type
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The Cognitive Services Speech Service authorization type. Currently


    unused.'
  syntax:
    content: SpeechServiceAuthorization_Type = 1004
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Type
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Endpoint
  id: SpeechServiceConnection_Endpoint
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceConnection_Endpoint
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The Cognitive Services Speech Service endpoint (url). Under normal


    circumstances, you shouldn''t have to use this property directly. Instead,


    construct a <xref:azure.cognitiveservices.speech.SpeechConfig> instance from a
    subscription key.



    > [!NOTE]

    > This endpoint is not the same as the endpoint used to obtain an access token.

    >'
  syntax:
    content: SpeechServiceConnection_Endpoint = 1001
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Endpoint
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EndpointId
  id: SpeechServiceConnection_EndpointId
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceConnection_EndpointId
  parent: azure.cognitiveservices.speech.PropertyId
  summary: "The Cognitive Services Custom Speech Service endpoint id. Under normal\n\
    \ncircumstances, you shouldn't have to use this property directly. Instead\n\n\
    set <xref:SpeechConfig.endpoint_id>.\n\n\n> [!NOTE]\n> The endpoint id is available\
    \ in the Custom Speech Portal, listed under\n>\n> \n>\n> Endpoint Details.\n>"
  syntax:
    content: SpeechServiceConnection_EndpointId = 1005
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EndpointId
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_IntentRegion
  id: SpeechServiceConnection_IntentRegion
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceConnection_IntentRegion
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The Language Understanding Service region. Under normal circumstances,


    you shouldn''t have to use this property directly. Instead use


    <xref:azure.cognitiveservices.speech.LanguageUnderstandingModel>.'
  syntax:
    content: SpeechServiceConnection_IntentRegion = 2003
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_IntentRegion
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Key
  id: SpeechServiceConnection_Key
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceConnection_Key
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The Cognitive Services Speech Service subscription key. If you are using


    an intent recognizer, you need to specify the LUIS endpoint key for your


    particular LUIS app. Under normal circumstances, you shouldn''t have to


    use this property directly. Instead, construct a


    <xref:azure.cognitiveservices.speech.SpeechConfig> instance from a subscription
    key.'
  syntax:
    content: SpeechServiceConnection_Key = 1000
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Key
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyHostName
  id: SpeechServiceConnection_ProxyHostName
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceConnection_ProxyHostName
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The host name of the proxy server used to connect to the Cognitive


    Services Speech Service. Under normal circumstances, you shouldn''t have


    to use this property directly. Instead, use


    <xref:SpeechConfig.set_proxy>.'
  syntax:
    content: SpeechServiceConnection_ProxyHostName = 1100
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyHostName
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPassword
  id: SpeechServiceConnection_ProxyPassword
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceConnection_ProxyPassword
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The password of the proxy server used to connect to the Cognitive


    Services Speech Service. Under normal circumstances, you shouldn''t have


    to use this property directly. Instead, use


    <xref:SpeechConfig.set_proxy>.'
  syntax:
    content: SpeechServiceConnection_ProxyPassword = 1103
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPassword
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPort
  id: SpeechServiceConnection_ProxyPort
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceConnection_ProxyPort
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The port of the proxy server used to connect to the Cognitive Services


    Speech Service. Under normal circumstances, you shouldn''t have to use


    this property directly. Instead, use <xref:SpeechConfig.set_proxy>.'
  syntax:
    content: SpeechServiceConnection_ProxyPort = 1101
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPort
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyUserName
  id: SpeechServiceConnection_ProxyUserName
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceConnection_ProxyUserName
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The user name of the proxy server used to connect to the Cognitive


    Services Speech Service. Under normal circumstances, you shouldn''t have


    to use this property directly. Instead, use


    <xref:SpeechConfig.set_proxy>.'
  syntax:
    content: SpeechServiceConnection_ProxyUserName = 1102
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyUserName
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoLanguage
  id: SpeechServiceConnection_RecoLanguage
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceConnection_RecoLanguage
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The spoken language to be recognized (in BCP-47 format). Under normal


    circumstances, you shouldn''t have to use this property directly. Instead,


    use <xref:SpeechConfig.speech_recognition_language>.'
  syntax:
    content: SpeechServiceConnection_RecoLanguage = 3001
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoLanguage
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoMode
  id: SpeechServiceConnection_RecoMode
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceConnection_RecoMode
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The Cognitive Services Speech Service recognition mode. Can be


    "INTERACTIVE", "CONVERSATION", "DICTATION". This property is intended to


    be read-only. The SDK is using it internally.'
  syntax:
    content: SpeechServiceConnection_RecoMode = 3000
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoMode
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Region
  id: SpeechServiceConnection_Region
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceConnection_Region
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The Cognitive Services Speech Service region. Under normal circumstances,


    you shouldn''t have to use this property directly. Instead, construct a


    <xref:azure.cognitiveservices.speech.SpeechConfig> instance from a subscription
    key, an endpoint


    or an authorization token.'
  syntax:
    content: SpeechServiceConnection_Region = 1002
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Region
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthLanguage
  id: SpeechServiceConnection_SynthLanguage
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceConnection_SynthLanguage
  parent: azure.cognitiveservices.speech.PropertyId
  syntax:
    content: SpeechServiceConnection_SynthLanguage = 3100
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthLanguage
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOutputFormat
  id: SpeechServiceConnection_SynthOutputFormat
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceConnection_SynthOutputFormat
  parent: azure.cognitiveservices.speech.PropertyId
  syntax:
    content: SpeechServiceConnection_SynthOutputFormat = 3102
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOutputFormat
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthVoice
  id: SpeechServiceConnection_SynthVoice
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceConnection_SynthVoice
  parent: azure.cognitiveservices.speech.PropertyId
  syntax:
    content: SpeechServiceConnection_SynthVoice = 3101
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthVoice
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationFeatures
  id: SpeechServiceConnection_TranslationFeatures
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceConnection_TranslationFeatures
  parent: azure.cognitiveservices.speech.PropertyId
  summary: Translation features. For internal use.
  syntax:
    content: SpeechServiceConnection_TranslationFeatures = 2002
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationFeatures
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationToLanguages
  id: SpeechServiceConnection_TranslationToLanguages
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceConnection_TranslationToLanguages
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The list of comma separated languages used as target translation


    languages. Under normal circumstances, you shouldn''t have to use this


    property directly. Instead use


    <xref:SpeechTranslationConfig.add_target_language> and


    <xref:SpeechTranslationConfig.target_languages>.'
  syntax:
    content: SpeechServiceConnection_TranslationToLanguages = 2000
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationToLanguages
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationVoice
  id: SpeechServiceConnection_TranslationVoice
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceConnection_TranslationVoice
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The name of the Cognitive Service Text to Speech Service voice. Under


    normal circumstances, you shouldn''t have to use this property directly.


    Instead set <xref:SpeechTranslationConfig.voice_name>.



    > [!NOTE]

    > Valid voice names can be found [here](https://aka.ms/csspeech/voicenames).

    >'
  syntax:
    content: SpeechServiceConnection_TranslationVoice = 2001
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationVoice
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonErrorDetails
  id: SpeechServiceResponse_JsonErrorDetails
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceResponse_JsonErrorDetails
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The Cognitive Services Speech Service error details (in JSON format).


    Under normal circumstances, you shouldn''t have to use this property


    directly. This property is available as


    <xref:RecognitionResult.error_json>.'
  syntax:
    content: SpeechServiceResponse_JsonErrorDetails = 5001
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonErrorDetails
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonResult
  id: SpeechServiceResponse_JsonResult
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceResponse_JsonResult
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The Cognitive Services Speech Service response output (in JSON format).


    This property is available as <xref:RecognitionResult.json>.'
  syntax:
    content: SpeechServiceResponse_JsonResult = 5000
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonResult
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RecognitionLatencyMs
  id: SpeechServiceResponse_RecognitionLatencyMs
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceResponse_RecognitionLatencyMs
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The recognition latency in milliseconds. Read-only, available on final


    speech/translation/intent results. This measures the latency between


    when an audio input is received by the SDK, and the moment the final


    result is received from the service. The SDK computes the time


    difference between the last audio fragment from the audio input that is


    contributing to the final result, and the time the final result is


    received from the speech service.



    > [!NOTE]

    > This property id was added in version 1.3.0.

    >'
  syntax:
    content: SpeechServiceResponse_RecognitionLatencyMs = 5002
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RecognitionLatencyMs
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse
  id: SpeechServiceResponse_RequestDetailedResultTrueFalse
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceResponse_RequestDetailedResultTrueFalse
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The requested Cognitive Services Speech Service response output format


    (simple or detailed). Under normal circumstances, you shouldn''t have to


    use this property directly. Instead use


    <xref:SpeechConfig.output_format>.'
  syntax:
    content: SpeechServiceResponse_RequestDetailedResultTrueFalse = 4000
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse
  id: SpeechServiceResponse_RequestProfanityFilterTrueFalse
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: SpeechServiceResponse_RequestProfanityFilterTrueFalse
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The requested Cognitive Services Speech Service response output profanity


    level. Currently unused.'
  syntax:
    content: SpeechServiceResponse_RequestProfanityFilterTrueFalse = 4001
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse
- fullName: azure.cognitiveservices.speech.PropertyId.Speech_LogFilename
  id: Speech_LogFilename
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: Speech_LogFilename
  parent: azure.cognitiveservices.speech.PropertyId
  syntax:
    content: Speech_LogFilename = 9001
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.Speech_LogFilename
- fullName: azure.cognitiveservices.speech.PropertyId.Speech_SessionId
  id: Speech_SessionId
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: Speech_SessionId
  parent: azure.cognitiveservices.speech.PropertyId
  summary: 'The session id. This id is a universally unique identifier (aka UUID)


    representing a specific binding of an audio input stream and the


    underlying speech recognition instance to which it is bound. Under normal


    circumstances, you shouldn''t have to use this property directly. Instead


    use <xref:SessionEventArgs.session_id>.'
  syntax:
    content: Speech_SessionId = 3002
    return:
      type:
      - azure.cognitiveservices.speech.PropertyId
  type: attribute
  uid: azure.cognitiveservices.speech.PropertyId.Speech_SessionId
references:
- fullName: azure.cognitiveservices.speech.PropertyId.AudioConfig_AudioSource
  isExternal: false
  name: AudioConfig_AudioSource
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_AudioSource
- fullName: azure.cognitiveservices.speech.PropertyId.AudioConfig_BitsPerSampleForCapture
  isExternal: false
  name: AudioConfig_BitsPerSampleForCapture
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_BitsPerSampleForCapture
- fullName: azure.cognitiveservices.speech.PropertyId.AudioConfig_DeviceNameForCapture
  isExternal: false
  name: AudioConfig_DeviceNameForCapture
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_DeviceNameForCapture
- fullName: azure.cognitiveservices.speech.PropertyId.AudioConfig_NumberOfChannelsForCapture
  isExternal: false
  name: AudioConfig_NumberOfChannelsForCapture
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_NumberOfChannelsForCapture
- fullName: azure.cognitiveservices.speech.PropertyId.AudioConfig_SampleRateForCapture
  isExternal: false
  name: AudioConfig_SampleRateForCapture
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_SampleRateForCapture
- fullName: azure.cognitiveservices.speech.PropertyId.CancellationDetails_Reason
  isExternal: false
  name: CancellationDetails_Reason
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.CancellationDetails_Reason
- fullName: azure.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonDetailedText
  isExternal: false
  name: CancellationDetails_ReasonDetailedText
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonDetailedText
- fullName: azure.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonText
  isExternal: false
  name: CancellationDetails_ReasonText
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonText
- fullName: azure.cognitiveservices.speech.PropertyId.LanguageUnderstandingServiceResponse_JsonResult
  isExternal: false
  name: LanguageUnderstandingServiceResponse_JsonResult
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.LanguageUnderstandingServiceResponse_JsonResult
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Token
  isExternal: false
  name: SpeechServiceAuthorization_Token
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Token
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Type
  isExternal: false
  name: SpeechServiceAuthorization_Type
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Type
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Endpoint
  isExternal: false
  name: SpeechServiceConnection_Endpoint
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Endpoint
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EndpointId
  isExternal: false
  name: SpeechServiceConnection_EndpointId
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EndpointId
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_IntentRegion
  isExternal: false
  name: SpeechServiceConnection_IntentRegion
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_IntentRegion
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Key
  isExternal: false
  name: SpeechServiceConnection_Key
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Key
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyHostName
  isExternal: false
  name: SpeechServiceConnection_ProxyHostName
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyHostName
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPassword
  isExternal: false
  name: SpeechServiceConnection_ProxyPassword
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPassword
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPort
  isExternal: false
  name: SpeechServiceConnection_ProxyPort
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPort
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyUserName
  isExternal: false
  name: SpeechServiceConnection_ProxyUserName
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyUserName
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoLanguage
  isExternal: false
  name: SpeechServiceConnection_RecoLanguage
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoLanguage
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoMode
  isExternal: false
  name: SpeechServiceConnection_RecoMode
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoMode
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Region
  isExternal: false
  name: SpeechServiceConnection_Region
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Region
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthLanguage
  isExternal: false
  name: SpeechServiceConnection_SynthLanguage
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthLanguage
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOutputFormat
  isExternal: false
  name: SpeechServiceConnection_SynthOutputFormat
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOutputFormat
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthVoice
  isExternal: false
  name: SpeechServiceConnection_SynthVoice
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthVoice
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationFeatures
  isExternal: false
  name: SpeechServiceConnection_TranslationFeatures
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationFeatures
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationToLanguages
  isExternal: false
  name: SpeechServiceConnection_TranslationToLanguages
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationToLanguages
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationVoice
  isExternal: false
  name: SpeechServiceConnection_TranslationVoice
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationVoice
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonErrorDetails
  isExternal: false
  name: SpeechServiceResponse_JsonErrorDetails
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonErrorDetails
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonResult
  isExternal: false
  name: SpeechServiceResponse_JsonResult
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonResult
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RecognitionLatencyMs
  isExternal: false
  name: SpeechServiceResponse_RecognitionLatencyMs
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RecognitionLatencyMs
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse
  isExternal: false
  name: SpeechServiceResponse_RequestDetailedResultTrueFalse
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse
- fullName: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse
  isExternal: false
  name: SpeechServiceResponse_RequestProfanityFilterTrueFalse
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse
- fullName: azure.cognitiveservices.speech.PropertyId.Speech_LogFilename
  isExternal: false
  name: Speech_LogFilename
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.Speech_LogFilename
- fullName: azure.cognitiveservices.speech.PropertyId.Speech_SessionId
  isExternal: false
  name: Speech_SessionId
  parent: azure.cognitiveservices.speech.PropertyId
  uid: azure.cognitiveservices.speech.PropertyId.Speech_SessionId
